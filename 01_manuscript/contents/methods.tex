%% -*- coding: utf-8 -*-
%% Timestamp: "2025-09-22 07:49:38 (ywatanabe)"
%% File: "/ssh:sp:/home/ywatanabe/proj/neurovista/paper/manuscript/src/methods.tex"
\section{Methods}

\subsection{Dataset and Study Design}
Data were obtained from the NeuroVista clinical trial \hlref{Cook2013} through the International Epilepsy Electrophysiology Portal (ieeg.org). The dataset comprised continuous intracranial electroencephalogram (iEEG) recordings from 15 human subjects with drug-resistant focal epilepsy, collected under ethical approval from the original clinical trial \hlref{Ethics}. Each subject was implanted with 16-channel platinum-iridium electrode arrays positioned around the \hl{clinically-identified seizure onset zone}, with signals sampled at 400 Hz and wirelessly transmitted to an external personal advisory device. The total dataset encompassed 4.1 TB of continuous recordings, with individual monitoring periods ranging from 6 months to over 2 years. From the complete dataset containing multiple seizure types, this study specifically analyzed 1,539 Type 1 (clinical) seizures with verified clinical manifestations across the 15 patients to ensure clinical relevance and interpretability of prediction algorithms.

	Seizures were classified following the original trial protocol into clinical (Type 1), clinically-equivalent (Type 2), and subclinical (Type 3) events. For this study, we focused exclusively on Type 1 seizures, which presented with observable clinical symptoms and clear electrographic patterns. Type 2 events (seizure-like events without clinical manifestations) and Type 3 events (subclinical seizures with distinct electrographic signatures) were excluded from analysis to maintain clinical relevance and ensure clear interpretation of prediction performance. Interictal control periods were selected from seizure-free intervals exceeding 4 hours from any Type 1 seizure event, matched for time of day to control for circadian influences on neural oscillations.

\subsection{Data Preprocessing and Quality Control}
The entire dataset was split into training, validation, and test sets following temporal progression to ensure pseudo-prospective evaluation. This temporal separation between training and testing phases prevents data leakage and provides realistic assessment of prediction performance. Training data comprised the earliest recordings, followed by validation data for hyperparameter tuning, with the most recent recordings reserved as held-out test data.

	Data integrity was maintained through cryptographic hashing (SHA-256) of all iEEG segments and seizure identifiers, enabling complete traceability and reproducibility of analyses. Each processed segment was stored with metadata including patient identifier, seizure type, exact timing, channel configuration, and processing parameters.

\subsection{Phase-Amplitude Coupling Analysis}
\subsubsection{GPU-Accelerated Implementation}
PAC strength was quantified using the modulation index (MI) \cite{Tort} following the Shannon entropy-based formulation: MI = 1 + $\\sum$(p $\\times$ log(p))/log(N), where p represents the normalized amplitude distribution across N phase bins and N = 18 bins (20° per bin). Computation was performed using a custom, standalone GPU-accelerated package (https://github.com/ywatanabe1989/gPAC) built on PyTorch with full vectorization across all frequency combinations. The implementation achieved approximately 100-fold speed improvement compared to conventional CPU-based methods through: (1) massive tensor operations eliminating nested loops, (2) optimized memory allocation utilizing up to 320GB total VRAM across multiple GPU nodes, and (3) batch processing with fp16 precision where appropriate. Processing leveraged the Spartan HPC system's distributed GPU architecture \hlref{Spartan} with automatic multi-GPU parallelization. Statistical significance was established using 200 surrogate datasets generated through circular phase shuffling, with PAC values z-score normalized relative to the surrogate distribution to eliminate spurious coupling.

	For each 1-minute non-overlapping time window, PAC was computed between 25 phase frequency bands (2.0-30.0 Hz) and 25 amplitude frequency bands (60.0-180.0 Hz), resulting in a 625-element PAC matrix per channel per time point. Frequency bands were generated using field-standard adaptive bandwidths: phase bands employed bandwidth = f/2 (e.g., 10 Hz center frequency spans 7.5-12.5 Hz), while amplitude bands used bandwidth = f/4 (e.g., 100 Hz center frequency spans 87.5-112.5 Hz). This approach yielded phase bands with bandwidths ranging from 0.5 Hz to 11.9 Hz and amplitude bands with bandwidths from 7.5 Hz to 40.0 Hz. Phase and amplitude information were extracted through bandpass filtering followed by Hilbert transformation to obtain instantaneous phase and amplitude envelopes. MI quantified coupling strength using the Shannon entropy-based formulation across 18 phase bins (20° each):

\begin{equation}
MI = 1 + \frac{\sum_{j=1}^{N} p_j \log(p_j)}{\log(N)}
\end{equation}

where $p_j$ represents the normalized amplitude probability in phase bin $j$, and $N = 18$ indicates the number of phase bins. Values range from 0 (uniform amplitude distribution) to 1 (maximum concentration in single phase bin). PAC values were z-score normalized using 200 surrogate datasets generated through circular phase shifts to control for spurious coupling effects.

	Missing values (NaN) in PAC computations arose from NaN values in recorded ECoG signals due to limited data type (int16), edge effects in filtering, or numerical instabilities in specific frequency combinations. NaN values found in ECoG signals were replaced with 0 while NaN values in PAC data were handled as is. Features derived from PAC matrices used nanmean, nanstd, and other NaN-aware statistical functions from NumPy to ensure robust computation despite missing values.

\subsubsection{Temporal Windows and Event Definition}
PAC dynamics were analyzed across multiple temporal scales relative to seizure onset. For each seizure event, computations spanned from -1440 minutes (24 hours) to +10 minutes post-onset, with adaptive temporal resolution optimized for seizure prediction. Timestamps relative to seizure onset ($t = 0$) were generated using conditional sampling:

\begin{equation}
t_i = \begin{cases}
-\text{round}(10^{(\log_{10}(60) + i \cdot \frac{\log_{10}(1440) - \log_{10}(60)}{N_{log}-1})}) & \text{for } i = 0, 1, \ldots, N_{log}-1 \text{ (logarithmic)} \\
-60 + j & \text{for } j = 0, 1, \ldots, 70 \text{ (linear)}
\end{cases}
\end{equation}

where logarithmic sampling from -1440 to -60 minutes provides denser resolution approaching seizure onset, and minute-by-minute linear sampling from -60 to +10 minutes captures critical peri-ictal to early ictal dynamics. The pre-ictal period was operationally defined as -60 to -5 minutes before seizure onset, based on previous seizure prediction studies \hlref{Kuhlmann2018} and clinical requirements for actionable warning times.

	For each Type 1 seizure, an equal number of interictal control segments were randomly sampled from the available seizure-free periods (>4 hours from any Type 1 seizure), ensuring balanced representation in subsequent classification analyses. Control segments were matched for time of day to account for circadian variations \hl{\cite{Pip}} in PAC patterns. All random sampling employed fixed seeds (SHA-256 hash-based) for complete reproducibility across analyses.

\subsection{Database Architecture and Storage}
Processed PAC data were organized in patient-specific SQLite3 databases with hierarchical structure optimized for HPC storage allocation and concurrent write operations to maximize parallel computation efficiency. Each database contained three primary components: (1) metadata tables storing patient demographics, seizure annotations, and processing parameters; (2) PAC data tables with zlib-compressed binary large objects (BLOBs) achieving \hl{70-90\%} storage reduction; (3) quality assurance tables tracking computation timestamps, software versions, and validation metrics. The database schema enabled efficient retrieval of specific temporal windows, frequency bands, or statistical measures without loading complete datasets into memory. Database operations were handled using the scitex.db module, a custom database interface optimized for scientific computing workflows.

	Data integrity was ensured through transaction-based writes with automatic rollback on errors, regular consistency checks comparing stored and computed checksums, and version control of all processing scripts with git-based tracking.

\subsection{Machine Learning Classification}
\subsubsection{Feature Engineering and Selection}
From the raw PAC matrices, we extracted 17 statistical features per time window: mean, standard deviation, median, minimum, maximum, 25th/50th/75th percentiles, kurtosis, skewness of PAC z-scores, plus specialized bimodality metrics from Gaussian mixture model (GMM) fitting including Ashman's D statistic, weight ratios, Bhattacharyya coefficient, and bimodality coefficient. Additionally, circular statistics of the preferred coupling phase were computed: circular mean, concentration (inverse of circular variance), circular skewness, and circular kurtosis.

	\hl{Feature selection employed a data-driven approach combining univariate statistical testing (Mann-Whitney U test with false discovery rate correction), recursive feature elimination with using performances in validation dataset.}

\subsubsection{Classification Algorithms}
\hl{Three classification approaches were evaluated: (1) logistic regression with L2 regularization for interpretable linear decision boundaries; (2) random forest with 100 estimators for capturing non-linear interactions; (3) support vector machines with radial basis function kernels for maximum-margin classification.} Additionally, a dummy classifier using stratified random predictions served as a baseline for performance comparison.

	For temporal context incorporation, we implemented sliding window classification where features from consecutive time points (window sizes of \hl{1, 3, 5, and 10 minutes}) were concatenated, allowing models to capture temporal evolution of PAC patterns. Window labeling followed the last time point in each window to maintain causal prediction constraints.

\subsubsection{Cross-Validation Strategy}
Model evaluation employed stratified time series cross-validation maintaining temporal ordering and class balance. Specifically, 5-fold stratified time series cross-validation was employed with training and validation data split by 0.8:0.2 ratio. The custom splitter ensured test data always occurred chronologically after training data, with configurable gaps (0-60 minutes) between training and test sets to prevent temporal leakage. Within-patient validation used these 5-fold splits preserving the temporal sequence, while across-patient evaluation employed leave-one-patient-out validation to assess generalization.

	Hyperparameter optimization utilized the validation set (20\% of training data) with \hl{grid search over regularization strengths} (logistic regression: C = 0.001 to 100), tree depths (random forest: 5 to 50), and kernel parameters (SVM: gamma = 0.001 to 10). \hl{Final models were retrained on complete training sets with optimal hyperparameters before evaluation on held-out test data}

\subsection{Performance Metrics and Statistical Analysis}
Classification performance was assessed using multiple complementary metrics addressing different aspects of seizure prediction requirements. Balanced accuracy weighted sensitivity and specificity equally, accounting for class imbalance. The area under the receiver operating characteristic curve (ROC-AUC) measured discrimination ability across all decision thresholds. Seizure-specific metrics included: sensitivity (proportion of correctly predicted seizures), time in warning (percentage of time under high-risk advisory), false positive rate per hour (FPR/h) normalized by prediction frequency, and alarm episode rate (consecutive false positives counted as single events).

	Clinical acceptability thresholds were defined based on previous implantable device studies: sensitivity ≥90\% for reliable seizure detection, FPR/h ≤0.0033 (equivalent to ≤0.2 alarm episodes/hour for 1-minute resolution), and time in warning ≤20\% to minimize patient burden. Statistical significance was assessed using permutation tests (10,000 iterations) for individual metrics and DeLong's test for ROC curve comparisons, with Bonferroni correction for multiple comparisons across patients and time windows.

\subsection{Visualization and Reporting}
Results were visualized through multiple complementary approaches. Comodulograms displayed PAC strength across all phase-amplitude frequency combinations as 2D heatmaps with color scaling defined based on baseline periods. Temporal evolution plots showed PAC dynamics from -60 to +10 minutes around seizures with confidence intervals from bootstrap resampling. Channel-wise topographic maps illustrated spatial distribution of PAC across the 16-electrode array. Statistical significance maps highlighted frequency pairs with consistent pre-ictal changes across seizures.

	All analyses were conducted using Python 3.10 with specialized libraries: PyTorch 2.0 for GPU computation, scikit-learn 1.3 for machine learning, MNE-Python 1.5 for electrophysiology-specific processing, and our custom SciTeX framework (https://github.com/ywatanabe1989/SciTeX-Code) for reproducible scientific computing. Complete code, processed features, and trained models are available at \hlref{DataAvailability} to facilitate reproduction and extension of our findings.

\label{sec:methods}

%%%% EOF